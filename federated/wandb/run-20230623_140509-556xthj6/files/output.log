



epoch: 10, loss: 0.62, time: 0.76:   2%|▋                         | 10/400 [00:07<04:59,  1.30it/s]



epoch: 18, loss: 0.62, time: 0.76:   4%|█▏                        | 18/400 [00:13<04:35,  1.38it/s]




epoch: 30, loss: 0.61, time: 0.74:   7%|█▉                        | 29/400 [00:21<04:16,  1.45it/s]



epoch: 38, loss: 0.61, time: 0.64:  10%|██▍                       | 38/400 [00:27<04:07,  1.46it/s]




epoch: 50, loss: 0.60, time: 0.44:  12%|███▎                      | 50/400 [00:35<04:02,  1.44it/s]



epoch: 58, loss: 0.59, time: 0.60:  14%|███▊                      | 58/400 [00:41<03:48,  1.50it/s]




epoch: 70, loss: 0.59, time: 0.52:  18%|████▌                     | 70/400 [00:49<03:50,  1.43it/s]



epoch: 78, loss: 0.59, time: 0.50:  20%|█████                     | 78/400 [00:55<03:35,  1.50it/s]




epoch: 90, loss: 0.58, time: 0.78:  22%|█████▊                    | 90/400 [01:03<03:49,  1.35it/s]



epoch: 98, loss: 0.58, time: 0.73:  24%|██████▎                   | 98/400 [01:09<03:41,  1.36it/s]




epoch: 110, loss: 0.59, time: 0.72:  27%|██████▌                 | 109/400 [01:17<03:18,  1.46it/s]



epoch: 118, loss: 0.57, time: 0.41:  30%|███████                 | 118/400 [01:23<03:15,  1.44it/s]




epoch: 130, loss: 0.57, time: 0.49:  32%|███████▋                | 129/400 [01:31<03:16,  1.38it/s]
epoch: 130, loss: 0.57, time: 0.49:  32%|███████▊                | 130/400 [01:32<03:11,  1.41it/s]
Traceback (most recent call last):
  File "src/main.py", line 93, in <module>
    main()
  File "src/main.py", line 74, in main
    trained_model = run_server(dataset, num_clients=args.c, epochs=args.epochs,
  File "/home/abenzaamia/MLP/federated/src/server.py", line 39, in run_server
    trained_weights = training_process(server_model, clients, num_clients, epochs, local_epochs, dataset, args)
  File "/home/abenzaamia/MLP/federated/src/fedmlp/train.py", line 66, in training_process
    w, loss = single_train_round(server_model, clients, local_epochs)
  File "/home/abenzaamia/MLP/federated/src/fedmlp/train.py", line 112, in single_train_round
    weights, loss = client.train(server_model_copy, local_epochs)
  File "/home/abenzaamia/MLP/federated/src/client.py", line 46, in train
    for _, (u, i, l) in enumerate(dataloader):
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 196, in __getitem__
    return tuple(tensor[index] for tensor in self.tensors)
  File "/home/abenzaamia/.venv/lib/python3.8/site-packages/torch/utils/data/dataset.py", line 196, in <genexpr>
    return tuple(tensor[index] for tensor in self.tensors)
KeyboardInterrupt